{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import pymongo as pm\n",
    "import json\n",
    "\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "import skmob\n",
    "from skmob.tessellation import tilers\n",
    "from bson import json_util\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HOST = 'mongodb://localhost:27017/'\n",
    "DATABASE = 'inter_test'\n",
    "COLLECTION = 'test'\n",
    "\n",
    "def initialize_mongoDB(host=HOST,database=DATABASE,collection=COLLECTION):\n",
    "    client = pm.MongoClient(host)\n",
    "    db = client[database]\n",
    "    col = db[collection]\n",
    "    return db,col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_path(api):\n",
    "    ROOT_DIR = os.path.abspath(os.curdir)\n",
    "    cdm_data_path = os.path.join(\n",
    "\t    ROOT_DIR,\n",
    "        f\"odysseus/{api}/\",\n",
    "\t    \"data\"\n",
    "    )\n",
    "    return cdm_data_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_available_data_per_zone(level='od_trips',api=\"city_data_manager\",DEBUG=False):\n",
    "    summary = {}\n",
    "    # Get list of cities\n",
    "    path = set_path(api)\n",
    "    list_subfolders_with_paths = [f.path for f in os.scandir(path) if f.is_dir()]\n",
    "    avalaible_cities = [os.path.basename(os.path.normpath(c)) for c in list_subfolders_with_paths]\n",
    "    for paths,city in zip(list_subfolders_with_paths,avalaible_cities):\n",
    "        data = retrieve_per_city_per_zone(city,paths,level=level,DEBUG=DEBUG)\n",
    "        summary[city] = data\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_per_city_per_zone(city,path,level=\"od_trips\",datatype = \"trips\",data_source_id=\"big_data_db\",DEBUG=False):\n",
    "    data = {}\n",
    "    if DEBUG:\n",
    "        print(\"PATH\",path)\n",
    "    for subdir, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            filepath = os.path.join(subdir,f)\n",
    "            if os.path.join(level,datatype,data_source_id) not in filepath:\n",
    "                continue\n",
    "\n",
    "            elif level==\"od_trips\" and filepath.endswith(\".csv\"):\n",
    "                if DEBUG:\n",
    "                    print(\"FILEPATH: \",filepath)\n",
    "                day_collect = groupby_zone_ods(filepath)\n",
    "                data[data_source_id] = day_collect\n",
    "    if DEBUG:\n",
    "        print(data)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_grid_as_gdf(total_bounds, crs, bin_side_length):\n",
    "    x_min, y_min, x_max, y_max = total_bounds\n",
    "    width = bin_side_length / 111320 * 1.2\n",
    "    height = bin_side_length / 111320 * 1.2\n",
    "    # width = bin_side_length / 0.706\n",
    "    # height = bin_side_length / 0.706\n",
    "    rows = int(np.ceil((y_max - y_min) / height))\n",
    "    cols = int(np.ceil((x_max - x_min) / width))\n",
    "    print(rows, cols)\n",
    "    x_left = x_min\n",
    "    x_right = x_min + width\n",
    "    y_top = y_max\n",
    "    y_bottom = y_max - height\n",
    "    polygons = []\n",
    "    for j in range(cols):\n",
    "        x_left = x_min\n",
    "        x_right = x_min + width\n",
    "        for i in range(rows):\n",
    "            polygons.append(\n",
    "                Polygon([\n",
    "                    (x_left, y_top),\n",
    "                    (x_right, y_top),\n",
    "                    (x_right, y_bottom),\n",
    "                    (x_left, y_bottom)]))\n",
    "            x_left = x_left + width\n",
    "            x_right = x_right + width\n",
    "        y_top = y_top - height\n",
    "        y_bottom = y_bottom - height\n",
    "\n",
    "    grid = gpd.GeoDataFrame({\"geometry\": polygons})\n",
    "\n",
    "    grid.crs = crs\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_zone_ods(filepath):    \n",
    "    cols = [\"start_time\", \"end_time\", 'start_longitude', 'start_latitude', 'end_longitude', 'end_latitude']\n",
    "\n",
    "    df = pd.read_csv(filepath, usecols=cols)\n",
    "    \n",
    "    df['start_time'] = pd.to_datetime(df['start_time'],utc=True).dt.to_pydatetime()\n",
    "    df['end_time'] = pd.to_datetime(df['end_time'],utc=True).dt.to_pydatetime()\n",
    "\n",
    "    df['year'] = df['end_time'].dt.year\n",
    "    df['month'] = df['end_time'].dt.month\n",
    "    df[\"end_day\"] = df['end_time'].dt.day\n",
    "    df[\"end_hour\"] = df['end_time'].dt.hour\n",
    "\n",
    "    df['year'] = df['start_time'].dt.year\n",
    "    df['month'] = df['start_time'].dt.month\n",
    "    df[\"start_day\"] = df['start_time'].dt.day\n",
    "    df[\"start_hour\"] = df['start_time'].dt.hour\n",
    "\n",
    "    origin_df = df[['start_time', 'start_longitude', 'start_latitude']]\n",
    "    destination_df = df[['end_time', 'end_longitude', 'end_latitude']]\n",
    "    destination_df['year'] = destination_df['end_time'].dt.year\n",
    "    destination_df['month'] = destination_df['end_time'].dt.month\n",
    "    origin_df['year'] = origin_df['start_time'].dt.year\n",
    "    origin_df['month'] = origin_df['start_time'].dt.month\n",
    "\n",
    "    \n",
    "    tessellation = get_city_grid_as_gdf(\n",
    "            (\n",
    "                min(origin_df.start_longitude.min(), destination_df.end_longitude.min(),\n",
    "                    origin_df.start_longitude.min(), destination_df.end_longitude.min()),\n",
    "                min(origin_df.start_latitude.min(), destination_df.end_latitude.min(),\n",
    "                   origin_df.start_latitude.min(), destination_df.end_latitude.min()),\n",
    "                max(origin_df.start_longitude.max(), destination_df.end_longitude.max(),\n",
    "                  origin_df.start_longitude.max(), destination_df.end_longitude.max()),\n",
    "                max(origin_df.start_latitude.max(), destination_df.end_latitude.max(),\n",
    "                    origin_df.start_latitude.max(), destination_df.end_latitude.max())\n",
    "            ),\n",
    "            \"epsg:4326\",\n",
    "            500\n",
    "        )\n",
    "\n",
    "    trips_origins = gpd.GeoDataFrame(\n",
    "        origin_df, geometry=gpd.points_from_xy(origin_df.start_longitude, origin_df.start_latitude))\n",
    "    trips_origins.crs = \"epsg:4326\"\n",
    "\n",
    "\n",
    "    trips_destinations = gpd.GeoDataFrame(\n",
    "        destination_df, geometry=gpd.points_from_xy(destination_df.end_longitude, destination_df.end_latitude))\n",
    "    trips_destinations.crs = \"epsg:4326\"\n",
    "\n",
    "    tessellation[\"tile_ID\"] = tessellation.index.values\n",
    "\n",
    "    trips_origins = gpd.sjoin(\n",
    "        trips_origins,\n",
    "        tessellation,\n",
    "        how='left',\n",
    "        op='intersects'\n",
    "    )\n",
    "    trips_destinations = gpd.sjoin(\n",
    "        trips_destinations,\n",
    "        tessellation,\n",
    "        how='left',\n",
    "        op='intersects'\n",
    "    )\n",
    "\n",
    "    df['destination_id'] = trips_destinations.tile_ID\n",
    "    df['origin_id'] = trips_origins.tile_ID\n",
    "\n",
    "    # valid zones\n",
    "    count_threshold=0\n",
    "\n",
    "    origin_zones_count = df.origin_id.value_counts()\n",
    "    dest_zones_count = df.destination_id.value_counts()\n",
    "\n",
    "\n",
    "    valid_origin_zones = origin_zones_count[(origin_zones_count > count_threshold)]\n",
    "    valid_dest_zones = dest_zones_count[(dest_zones_count > count_threshold)]\n",
    "\n",
    "\n",
    "    valid_zones = valid_origin_zones.index.intersection(\n",
    "                    valid_dest_zones.index\n",
    "            ).astype(int)\n",
    "\n",
    "    tessellation = tessellation.loc[valid_zones]\n",
    "\n",
    "    df = df.loc[\n",
    "                (df.origin_id.isin(valid_zones)) & (\n",
    "                    df.destination_id.isin(valid_zones)\n",
    "                )]\n",
    "\n",
    "    origin_counts = df [['year', 'month', 'start_day', 'start_hour', 'origin_id']]\n",
    "    origin_counts['occurrance'] = 1\n",
    "    origin_counts = origin_counts.groupby(\n",
    "        ['year', 'month', 'start_day', 'start_hour', 'origin_id'], as_index=False\n",
    "    ).sum([\"occurance\"])\n",
    "    \n",
    "    destination_counts = df [['year', 'month', 'end_day', 'end_hour', 'destination_id']]\n",
    "    destination_counts['occurrance'] = 1\n",
    "    destination_counts = destination_counts.groupby(\n",
    "        ['year', 'month', 'end_day', 'end_hour', 'destination_id'], as_index=False\n",
    "    ).sum([\"occurance\"])\n",
    "    \n",
    "    og_ans = build_raw_answer_monthly_zone(origin_counts)\n",
    "    dest_ans = build_raw_answer_monthly_zone(destination_counts)\n",
    "\n",
    "    \n",
    "    return og_ans, dest_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_raw_answer_monthly_zone(df, DEBUG=False):\n",
    "\n",
    "    if all([c in df.columns for c in ['start_day', 'start_hour', 'origin_id']]):\n",
    "        df = df.drop(['start_day', 'start_hour'], axis=1)\n",
    "        df = df.groupby(\n",
    "                ['year', 'month', 'origin_id']\n",
    "            ).sum([\"occurrance\"])\n",
    "        \n",
    "    elif all([c in df.columns for c in ['end_day', 'end_hour', 'destination_id']]):\n",
    "        df = df.drop(['end_day', 'end_hour'], axis=1)\n",
    "        df = df.groupby(\n",
    "            ['year', 'month', 'destination_id']\n",
    "        ).sum([\"occurance\"])\n",
    "    else:\n",
    "        print('Errore')\n",
    "        \n",
    "    final_dict = {}\n",
    "    for index, row in df.iterrows():\n",
    "        value = row['occurrance']\n",
    "        \n",
    "        if index[0] in final_dict.keys() and index[1] in final_dict[index[0]].keys() and index[2] in final_dict[index[0]][index[1]].keys():\n",
    "            final_dict[index[0]][index[1]][index[2]].append(0)\n",
    "        elif index[0] in final_dict.keys() and index[1] in final_dict[index[0]].keys() :\n",
    "            final_dict[index[0]][index[1]].update({index[2]:[value]})\n",
    "        elif index[0] in final_dict.keys() :\n",
    "            final_dict[index[0]].update({index[1]:{index[2]:[value]}})\n",
    "        else:\n",
    "            final_dict.update({index[0]:{index[1]:{index[2]:[value]}}})\n",
    "    \n",
    "    db,col = initialize_mongoDB()\n",
    "    id_object = col.insert_one(json.loads(json_util.dumps(final_dict)))\n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/andrea/Desktop/ICT4SS/Interdisciplinary Project/odysseus/odysseus/webapp/apis/api_cityDataManager/odysseus/city_data_manager/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c4fed1300557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_available_data_per_zone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mjsonify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-66f92255cea4>\u001b[0m in \u001b[0;36msummary_available_data_per_zone\u001b[0;34m(level, api, DEBUG)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Get list of cities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlist_subfolders_with_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mavalaible_cities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_subfolders_with_paths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_subfolders_with_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavalaible_cities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/andrea/Desktop/ICT4SS/Interdisciplinary Project/odysseus/odysseus/webapp/apis/api_cityDataManager/odysseus/city_data_manager/data'"
     ]
    }
   ],
   "source": [
    "summary = summary_available_data_per_zone(DEBUG=False)\n",
    "jsonify(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
